{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:08:27.498648Z",
     "start_time": "2023-06-28T19:08:26.775363Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "topics_url = 'https://www.ted.com/topics'\n",
    "response = requests.get(topics_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# get topics under \"div class=\"text-sm xl:text-base xl:leading-md\"\n",
    "for topic in soup.find_all('div', class_='text-sm xl:text-base xl:leading-md'):\n",
    "    topics.append(topic.text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'activism'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter Singer \n",
      "Jun 2023\n",
      " /talks/peter_singer_a_modern_argument_for_the_rights_of_animals \n",
      "\n",
      "A modern argument for the rights of animals\n",
      "\n",
      "\n",
      "Sahar Zand \n",
      "Jun 2023\n",
      " /talks/sahar_zand_why_iranians_are_cutting_their_hair_for_woman_life_freedom \n",
      "\n",
      "Why Iranians are cutting their hair for \"Woman, Life, Freedom\"\n",
      "\n",
      "\n",
      "Golshifteh Farahani \n",
      "May 2023\n",
      " /talks/golshifteh_farahani_woman_life_freedom_in_iran_and_what_it_means_for_the_rest_of_the_world \n",
      "\n",
      "\"Woman, Life, Freedom\" in Iran — and what it means for the rest of the world\n",
      "\n",
      "\n",
      "Nadya Tolokonnikova \n",
      "Apr 2023\n",
      " /talks/nadya_tolokonnikova_pussy_riot_s_powerful_message_to_vladimir_putin \n",
      "\n",
      "Pussy Riot's powerful message to Vladimir Putin\n",
      "\n",
      "\n",
      "Tiffani Ashley Bell \n",
      "Mar 2023\n",
      " /talks/tiffani_ashley_bell_how_one_small_idea_led_to_1_million_of_paid_water_bills \n",
      "\n",
      "How one small idea led to $1 million of paid water bills\n",
      "\n",
      "\n",
      "Channing Gerard Joseph \n",
      "Feb 2023\n",
      " /talks/channing_gerard_joseph_how_black_queer_culture_shaped_history \n",
      "\n",
      "How Black queer culture shaped history\n",
      "\n",
      "\n",
      "Luisa Neubauer \n",
      "Jan 2023\n",
      " /talks/luisa_neubauer_the_fairy_tales_of_the_fossil_fuel_industry_and_a_better_climate_story \n",
      "\n",
      "The fairy tales of the fossil fuel industry — and a better climate story\n",
      "\n",
      "\n",
      "Xavier Cortada \n",
      "Dec 2022\n",
      " /talks/xavier_cortada_a_creative_approach_to_community_climate_action \n",
      "\n",
      "A creative approach to community climate action\n",
      "\n",
      "\n",
      "Angélique Kidjo and Femi Oke \n",
      "Nov 2022\n",
      " /talks/angelique_kidjo_and_femi_oke_why_joy_is_a_state_of_mind \n",
      "\n",
      "Why joy is a state of mind\n",
      "\n",
      "\n",
      "Lindsey Schneider \n",
      "Nov 2022\n",
      " /talks/lindsey_schneider_whose_land_are_you_on_what_to_know_about_the_indigenous_land_back_movement \n",
      "\n",
      "Whose land are you on? What to know about the Indigenous Land Back movement\n",
      "\n",
      "\n",
      "Tamana Ayazi and Kat Craig \n",
      "Nov 2022\n",
      " /talks/tamana_ayazi_and_kat_craig_the_danger_and_devotion_of_fighting_for_women_in_afghanistan \n",
      "\n",
      "The danger and devotion of fighting for women in Afghanistan\n",
      "\n",
      "\n",
      "Fehinti Balogun \n",
      "Nov 2022\n",
      " /talks/fehinti_balogun_how_to_find_your_voice_for_climate_action \n",
      "\n",
      "How to find your voice for climate action\n",
      "\n",
      "\n",
      "Vanessa Nakate and Mary Robinson \n",
      "Nov 2022\n",
      " /talks/vanessa_nakate_and_mary_robinson_the_global_opportunity_to_accelerate_africa_s_sustainable_future \n",
      "\n",
      "The global opportunity to accelerate Africa's sustainable future\n",
      "\n",
      "\n",
      "Jane Fonda \n",
      "Oct 2022\n",
      " /talks/jane_fonda_how_to_transform_your_climate_concern_into_action \n",
      "\n",
      "How to transform your climate concern into action\n",
      "\n",
      "\n",
      "Meghan Hussey \n",
      "Oct 2022\n",
      " /talks/meghan_hussey_4_ways_to_design_a_disability_friendly_future \n",
      "\n",
      "4 ways to design a disability-friendly future\n",
      "\n",
      "\n",
      "Adjany Costa \n",
      "Oct 2022\n",
      " /talks/adjany_costa_lasting_conservation_led_by_indigenous_heritage \n",
      "\n",
      "Lasting conservation, led by Indigenous heritage\n",
      "\n",
      "\n",
      "Majora Carter \n",
      "Sep 2022\n",
      " /talks/majora_carter_you_don_t_have_to_leave_your_neighborhood_to_live_in_a_better_one \n",
      "\n",
      "You don't have to leave your neighborhood to live in a better one\n",
      "\n",
      "\n",
      "Sara Lomelin \n",
      "Sep 2022\n",
      " /talks/sara_lomelin_your_invitation_to_disrupt_philanthropy \n",
      "\n",
      "Your invitation to disrupt philanthropy\n",
      "\n",
      "\n",
      "Megan Reitz \n",
      "Sep 2022\n",
      " /talks/megan_reitz_how_to_lead_in_the_new_era_of_employee_activism \n",
      "\n",
      "How to lead in the new era of employee activism\n",
      "\n",
      "\n",
      "Peggy Shepard \n",
      "Aug 2022\n",
      " /talks/peggy_shepard_how_to_build_an_equitable_and_just_climate_future \n",
      "\n",
      "How to build an equitable and just climate future\n",
      "\n",
      "\n",
      "Samir Ibrahim, MyVerse and Kristen Warren \n",
      "Jul 2022\n",
      " /talks/samir_ibrahim_myverse_and_kristen_warren_how_hip_hop_can_make_climate_action_cool \n",
      "\n",
      "How hip-hop can make climate action cool\n",
      "\n",
      "\n",
      "Zahra Biabani \n",
      "Jul 2022\n",
      " /talks/zahra_biabani_the_eco_creators_helping_the_climate_through_social_media \n",
      "\n",
      "The eco-creators helping the climate through social media\n",
      "\n",
      "\n",
      "Ayana Elizabeth Johnson \n",
      "Jun 2022\n",
      " /talks/ayana_elizabeth_johnson_how_to_find_joy_in_climate_action \n",
      "\n",
      "How to find joy in climate action\n",
      "\n",
      "\n",
      "Margaret Levi \n",
      "May 2022\n",
      " /talks/margaret_levi_how_labor_unions_shape_society \n",
      "\n",
      "How labor unions shape society\n",
      "\n",
      "\n",
      "Bektour Iskender \n",
      "May 2022\n",
      " /talks/bektour_iskender_the_crime_fighting_power_of_cross_border_investigative_journalism \n",
      "\n",
      "The crime-fighting power of cross-border investigative journalism\n",
      "\n",
      "\n",
      "Srishti Bakshi \n",
      "May 2022\n",
      " /talks/srishti_bakshi_my_long_walk_across_india_for_women_s_freedom \n",
      "\n",
      "My long walk across India for women's freedom\n",
      "\n",
      "\n",
      "Sue Natali \n",
      "May 2022\n",
      " /talks/sue_natali_how_ancient_arctic_carbon_threatens_everyone_on_the_planet \n",
      "\n",
      "How ancient Arctic carbon threatens everyone on the planet\n",
      "\n",
      "\n",
      "Becca Heller \n",
      "May 2022\n",
      " /talks/becca_heller_a_safe_pathway_to_resettlement_for_migrants_and_refugees \n",
      "\n",
      "A safe pathway to resettlement for migrants and refugees\n",
      "\n",
      "\n",
      "Selina Neirok Leem \n",
      "Mar 2022\n",
      " /talks/selina_neirok_leem_climate_change_isn_t_a_distant_threat_it_s_our_reality \n",
      "\n",
      "Climate change isn't a distant threat — it's our reality\n",
      "\n",
      "\n",
      "Jimmie Briggs \n",
      "Mar 2022\n",
      " /talks/jimmie_briggs_3_things_men_can_do_to_promote_gender_equity \n",
      "\n",
      "3 things men can do to promote gender equity\n",
      "\n",
      "\n",
      "Benedetta Berti and Evelien Borgman \n",
      "Mar 2022\n",
      " /talks/benedetta_berti_and_evelien_borgman_what_does_it_mean_to_be_a_refugee_jan_2018 \n",
      "\n",
      "What does it mean to be a refugee?\n",
      "\n",
      "\n",
      "Ozawa Bineshi Albert \n",
      "Feb 2022\n",
      " /talks/ozawa_bineshi_albert_climate_action_needs_new_frontline_leadership \n",
      "\n",
      "Climate action needs new frontline leadership\n",
      "\n",
      "\n",
      "Rosamund Adoo-Kissi-Debrah \n",
      "Feb 2022\n",
      " /talks/rosamund_adoo_kissi_debrah_the_tragedy_of_air_pollution_and_an_urgent_demand_for_clean_air \n",
      "\n",
      "The tragedy of air pollution — and an urgent demand for clean air\n",
      "\n",
      "\n",
      "Candace Parker \n",
      "Jan 2022\n",
      " /talks/candace_parker_how_to_break_down_barriers_and_not_accept_limits \n",
      "\n",
      "How to break down barriers and not accept limits\n",
      "\n",
      "\n",
      "Nkosilathi Nyathi \n",
      "Dec 2021\n",
      " /talks/nkosilathi_nyathi_a_next_generation_solution_to_the_climate_crisis \n",
      "\n",
      "A next-generation solution to the climate crisis\n",
      "\n",
      "\n",
      "Shabana Basij-Rasikh \n",
      "Dec 2021\n",
      " /talks/shabana_basij_rasikh_the_dream_of_educating_afghan_girls_lives_on \n",
      "\n",
      "The dream of educating Afghan girls lives on\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topiclanding = \"https://www.ted.com/talks?topics[]=activism\"\n",
    "response = requests.get(topiclanding)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#find speaker name under h4 class=\"h12 talk-link__speaker\"\n",
    "speaker = soup.find_all('h4', class_='h12 talk-link__speaker')\n",
    "posted = soup.find_all('span', class_='meta__val')\n",
    "# find href of the post under h4 tag a \n",
    "link = soup.find_all('h4', class_='h9 m5 f-w:700')\n",
    "title = link\n",
    "\n",
    "for i in range(len(speaker)):\n",
    "    print(speaker[i].text, posted[i].text, link[i].find('a')['href'], title[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:09:32.869680Z",
     "start_time": "2023-06-28T19:09:32.862375Z"
    }
   },
   "outputs": [],
   "source": [
    "pages = [str(i) for i in range(0, 1, 1)] # page iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:09:36.176087Z",
     "start_time": "2023-06-28T19:09:36.165151Z"
    }
   },
   "outputs": [],
   "source": [
    "page_urls = []\n",
    "for page in pages:\n",
    "    base_url = 'https://www.ted.com/talks?page='+page\n",
    "    page_urls.append(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:09:37.916956Z",
     "start_time": "2023-06-28T19:09:37.908048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ted.com/talks?page=0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:10:08.652021Z",
     "start_time": "2023-06-28T19:09:43.984651Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading page 1/1: : 151it [01:35,  1.58it/s]                   1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "talks = [] # also called add_links\n",
    "\n",
    "# find href links to talks in page content under <a> tags\n",
    "pbar = tqdm(total=len(page_urls), dynamic_ncols=True, colour= 'green')\n",
    "for i, page in enumerate(page_urls):\n",
    "    page = requests.get(page_urls[i])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    for link in soup.find_all('a'):\n",
    "        time.sleep(0.5)\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f'Downloading page {i+1}/{len(page_urls)}', refresh=True)\n",
    "\n",
    "        if link.has_attr('href') and link['href'].startswith('/talks/'):\n",
    "            ted_url = 'https://www.ted.com'\n",
    "            #check if link already exists in talks list\n",
    "            if ted_url + link['href'] not in talks:\n",
    "                #concat 'https://www.ted.com' + link['href'] to talks list\n",
    "                talks.append(ted_url + link['href'])\n",
    "            else:\n",
    "        # if link already exists in talks list, skip it\n",
    "                continue\n",
    "            time.sleep(0.5)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-28T19:09:30.419344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ted.com/talks/shane_campbell_staton_how_life_on_earth_adapts_to_you_and_me'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:10:16.275668Z",
     "start_time": "2023-06-28T19:10:16.268424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I became obsessed with the relationship between the brain and the mind after suffering a series of concussions playing football and rugby in college. I felt my mind change for years after. I was studying computers at the time, and it felt as though I had damaged my hardware and that my software was running differently. Over the following years, a close friend suffered a serious neck injury and multiple friends and family members were struggling with crippling mental health issues. All around me, people that I loved dearly were being afflicted by ailments of the nervous system or the mind. I was grappling with all of this while pursuing an MFA in Design and Technology at Parsons when a friend and fellow student showed me an open-source tutorial on how to build a low-cost single-channel EEG system to detect brain activity. After a couple long nights of hacking and tinkering, I saw my brainwaves dancing across the screen for the very first time. And that moment changed my life. In that moment, I felt as though I had the possibility to help myself and the people I loved. And I also realized that I couldn&apos;t do it alone. I needed help. So in 2013, in Brooklyn, with some like-minded friends, I started OpenBCI, an open-source neurotechnology company. In the beginning, our goal was to build an inward-pointing telescope and to share the blueprints with the world so that anybody with a computer could begin peering into their own brain. At first, we were an EEG-only company. We sold brain sensors to measure brain activity. I thought that&apos;s what people wanted. But over time, we discovered people doing very strange things with our technology. Some people were connecting the equipment to the stomach to measure the neurons in the gut and study gut-brain connection and the microbiome. Others were using the tools to build new muscle sensors and controllers for prosthetics and robotics. And some were designing new devices and peripheral add-ons that could be connected to the platform to measure new types of data that I had never heard of before. What we learned from all of this is that the brain by itself is actually quite boring. Turns out brain data alone lacks context. And what we ultimately care about is not the brain, but the mind, consciousness, human cognition. When we have things like EMG sensors to measure muscle activity or ECG sensors to measure heart activity, eye trackers and even environmental sensors to measure the world around us, all of this makes the brain data much more useful. But the organs around our body, our sensory receptors, are actually much easier to collect data from than the brain, and also arguably much more important for determining the things that we actually care about: emotions, intentions and the mind overall. Additionally, we realized that people weren&apos;t just interested in reading from the brain and the body. They were also interested in modulating the mind through various types of sensory stimulation. Things like light, sound, haptics and electricity. It&apos;s one thing to record the mind, it&apos;s another to modulate it. The idea of a combined system that can both read from and write to the brain or body is referred to as a closed-loop system or bidirectional human interface. This concept is truly profound, and it will define the next major revolution in computing technology. When you have products that not just are designed for the average user but are designed to actually adapt to their user, that&apos;s something truly special. When we know what the data of an emotion or a feeling looks like and we know how to make that data go up or down, then using AI, we can build constructive or destructive interference patterns to either amplify or suppress those emotions or feelings. In the very near future, we will have computers that we are resonantly and subconsciously connected to, enabling empathetic computing for the very first time. In 2018, we put these learnings to work and began development of a new tool for cognitive exploration. Named after my friend Gael, who passed from ALS in 2016, we call it Galea. It’s a multimodal bio-sensing headset, and it is absolutely packed with sensors. It can measure the user’s heart, skin, muscles, eyes and brain, and it combines that capability with head-mounted displays or augmented and virtual reality headsets. Additionally, we&apos;re exploring the integration of non-invasive electrical neural stimulation as a feature. The Galea software suite can turn the raw sensor data into meaningful metrics. With some of the sensors, we&apos;re able to provide new forms of real-time interactivity and control. And with all of the sensors, we&apos;re able to make quantifiable inferences about high-level states of mind, things like stress, fatigue, cognitive workload and focus. In 2019, a legendary neurohacker by the name of Christian Bayerlein reached out to me. He was actually one of our very first Kickstarter backers when we got started, early on. Christian was a very smart, intelligent, happy-go-lucky and easygoing guy. And so I worked up the courage to ask him, &quot;Hey, Christian, can we connect you to our sensors?&quot; At which point he said, &quot;I thought you would never ask.&quot; (Laughter) So after 20 minutes, we had him rigged up to a bunch of electrodes, and we provided him with four new inputs to a computer. Little digital buttons, that he could control voluntarily. This essentially doubled his number of inputs to a computer. Years later, after many setbacks due to COVID, we flew to Germany to work with Christian in person to implement the first prototype of what we&apos;re going to be demoing here today. Christian then spent months training with that prototype and sending his data across the Atlantic to us in Brooklyn from Germany and flying a virtual drone in our offices. The first thing that we did was scour Christian&apos;s body for residual motor function. We then connected electrodes to the four muscles that he had the most voluntary control over, and then we turned those muscles into digital buttons. We then applied some smart filtering and signal processing to adapt those buttons into something more like a slider or a digital potentiometer. After that, we turned those four sliders and mapped them to a new virtual joystick. Christian then combined that new joystick with the joystick that he uses with his lip to control his wheelchair, and with the two joysticks combined, Christian finally had control over all the manual controls of a drone. I’m going to stop talking about it, and we’re going to show you. Christian, welcome. (Applause) At this point, I&apos;m going to ask everybody to turn off your Bluetooth and put your phones in airplane mode so that you don&apos;t get hit in the face with a drone. (Laughter) How are you feeling, Christian? Christian Bayerlein: Yeah, let&apos;s do it. Conor Russomanno: Awesome. This is a heads-up display that&apos;s showing all of Christian&apos;s biometric data, as well as some information about the drone. On the left here, we can see Christian&apos;s muscle data. Christian is now going to attempt to fly the drone. How are you feeling, Christian, feeling good? CB: Yes. CR: All right. Rock and roll. Let&apos;s take this up for a joyride. Whenever you&apos;re ready. CB: I&apos;m ready. (Applause and cheers) CR: All right, take her up. And now let&apos;s do something we probably shouldn&apos;t do and fly it over the audience. (Laughter) (Cheers and applause) Alright, actually, let’s do this. I&apos;m going to ask for people to call out some commands in the audience. So how about you? Straight forward. Straight forward. (Laughter) Alright. How about you? Man: Up! (Laughter) CR: Not down. Oh, he&apos;s doing what he wants right now. Amazing. (Cheers and applause) Alright, let’s bring it back. And what I&apos;m going to do right now is take control of the controller so that you guys know that there isn&apos;t someone backstage flying this drone. All right, Christian, you&apos;re alright with that? CB: Yeah. CR: Unplug. Forward. And we&apos;re going to land this guy now. CB: I think I was better than you. (Laughter) (Applause) CR: Amazing. (Applause) Now I&apos;m going to unplug it so it doesn&apos;t turn on on its own. Perfect. Christian has repurposed dormant muscles from around his body for extended and augmented interactivity. We have turned those muscles into a generic controller that in this case we&apos;ve mapped into a drone, but what&apos;s really cool is that joystick can be applied to anything. Another thing that&apos;s really cool is that even in individuals who are not living with motor disabilities, there exist dozens of dormant muscles around the body that we can tap into for augmented and expanded control interactivity. And lastly, all the code related to that virtual joystick, we&apos;re going to open source so that you can implement it and improve upon it. There&apos;s three things that have stood out to me from working on this project and many others over the years. One, we cannot conflate the brain with the mind. In order to understand emotions and tensions and the mind overall, we have to measure data from all over the body, not just the brain. Two, open-source technology access and literacy is one way that we can combat the potential ethical challenges we face in introducing neural technology to society. But that&apos;s not enough. We have to do much, much more than that. It&apos;s very important, imperative, that we set up guardrails and design the future that we want to live in. Three. It&apos;s the courage and resilience of trailblazers like Christian who don&apos;t get bogged down by what they can&apos;t do, but instead strive to prove that the impossible is in fact possible. (Applause) And since none of this would have been possible without you, Christian, the stage is yours. CB: Yeah, hi, everybody. Audience: Hi. CB: I&apos;m excited to be here today. I was born with a genetic condition that affects my mobility and requires me to have assistance. Despite my disability, I&apos;m a very happy and fulfilled person. What truly holds me back are not my physical limitations. It&apos;s rather the barriers in the environment. I&apos;m a tech nerd and political activist. I believe that technology can empower disabled people. It can help create a better, more inclusive and accessible world for everyone. This demonstration is a perfect example. We saw what&apos;s possible when cutting edge technology is combined with human curiosity and creativity. So let&apos;s build tools that empower people, applications that break down barriers and systems that unlock a world of possibilities. I think that&apos;s an idea worth spreading. Thank you. (Cheers and applause)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# find views of talk under <div class=\"text-sm w-full truncate text-gray-900\" data-testid=\"talk-meta\">\n",
    "response = requests.get(talks[5])\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "schema = soup.find('head').find('script', type='application/ld+json').text\n",
    "schema = json.loads(schema)\n",
    "schema.get('transcript')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(total=len(talks), dynamic_ncols=True, colour= 'green')\n",
    "\n",
    "for i, ad in enumerate(talks):\n",
    "    #-------create dataframe--------#\n",
    "    df = pd.DataFrame(columns=[\"author\", \"talk\", \"description\", \"likes\", \"views\"])\n",
    "\n",
    "    time.sleep(2)\n",
    "    pbar.update(1)\n",
    "    response = requests.get(talks[i])\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "\n",
    "    #--------Title Schema------------#\n",
    "    title_schema = soup.find('head').find('title').text.strip()\n",
    "\n",
    "    #--------Description Schema------------#\n",
    "    try:\n",
    "        description_schema = soup.find('head').find('meta', attrs={'name':'description'})['content'].strip()\n",
    "\n",
    "    except:\n",
    "        description_schema = ''\n",
    "\n",
    "    #--------Likes Schema------------#\n",
    "    likes_schema = soup.find_all('span')[0].get_text().strip()\n",
    "\n",
    "    #--------Views Schema------------#\n",
    "    views_schema = soup.find_all('div', class_='text-sm w-full truncate text-gray-900')\n",
    "\n",
    "\n",
    "    # get author name from title \n",
    "    author = title_schema.split(':')[0]\n",
    "    talk = title_schema.split(':')[1].strip().replace('| TED Talk', '')\n",
    "    description = description_schema\n",
    "    likes = likes_schema.replace('(', '').replace(')', '')\n",
    "    try: \n",
    "        views = views_schema[0].get_text().strip().split()[0]\n",
    "    except:\n",
    "        views = 0\n",
    "\n",
    "    pbar.set_description(f'Downloading {talk}', refresh=True)\n",
    "\n",
    "    # add to dataframe\n",
    "    df = df.append({'author': author, 'talk': talk, 'description': description, 'likes': likes, 'views': views}, ignore_index=True)\n",
    "\n",
    " # ----------------------------------------Saving to Database--------------------------------------------#\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect('talks.db')\n",
    "    cur = conn.cursor()\n",
    "                \n",
    "    for i in range(len(df)):\n",
    "        cur.execute(\"INSERT INTO talks (author, talk, description, likes, views) VALUES (?, ?, ?, ?, ?)\", (df.iloc[i]['author'], df.iloc[i]['talk'], df.iloc[i]['description'], df.iloc[i]['likes'], df.iloc[i]['views']))\n",
    "    conn.commit()\n",
    "\n",
    "    time.sleep(1)\n",
    "    pbar.set_description(f'Adding {talk} to database', refresh=True)\n",
    "    pbar.update(1)\n",
    "\n",
    "    time.sleep(1)\n",
    "    cur.execute(\"SELECT * FROM talks\")\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    pbar.set_description(f\"There are {len(rows)} records in the database\", refresh=True)\n",
    "    conn.close()\n",
    "    time.sleep(1)\n",
    "pbar.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
