{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/Users/patrickokwir/Desktop/Git_Projects/Ted-Talks-Recommender-System/Data_output/ted_talk_clean_merged_bert.csv'\n",
    "df = pd.read_csv(data, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_data(df, batch_size=20):\n",
    "    sum_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    summarizer = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    num_records = len(df)\n",
    "    num_batches = (num_records + batch_size - 1) // batch_size\n",
    "\n",
    "    embeddings_list = []\n",
    "    with tqdm(total=num_batches, desc=\"Processing\", colour='green') as pbar:\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = min((batch_idx + 1) * batch_size, num_records)\n",
    "            batch_df = df.iloc[batch_start:batch_end]\n",
    "\n",
    "            tokens = {'input_ids': [], 'attention_mask': []}\n",
    "            for _, row in batch_df.iterrows():\n",
    "\n",
    "                input_transcript = sum_tokenizer(row['transcript'], max_length=1024, return_tensors=\"pt\")\n",
    "                summary_ids = summarizer.generate(input_transcript[\"input_ids\"], num_beams=2, min_length=10, max_length=300)\n",
    "                summary = sum_tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "                new_tokens = tokenizer.encode_plus(summary,\n",
    "                    max_length=512,\n",
    "                    truncation=True,\n",
    "                    padding='max_length',\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "                tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "            tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "            tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**tokens)\n",
    "                embeddings = outputs.last_hidden_state\n",
    "\n",
    "                mask = tokens['attention_mask'].unsqueeze(-1).expand(embeddings.size()).float()\n",
    "                mask_embeddings = embeddings * mask\n",
    "                summed = torch.sum(mask_embeddings, dim=1)\n",
    "                counts = torch.clamp(mask.sum(dim=1), min=1e-9)\n",
    "                mean_pooled = summed / counts\n",
    "\n",
    "            embeddings_list.append(mean_pooled.detach().cpu().numpy())\n",
    "            pbar.update(1)\n",
    "\n",
    "    embeddings = np.concatenate(embeddings_list, axis=0)\n",
    "    cosine_sim = cosine_similarity(embeddings, embeddings)\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate pipeline \n",
    "def process_data(df):\n",
    "    #instantiate a pipeline step\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    #instantiate a pipeline step\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    #instantiate a pipeline step\n",
    "    tokens = {'input_ids': [], 'attention_mask': []}\n",
    "    for row in df_rows:\n",
    "        new_tokens = tokenizer.encode_plus(df['transcript'][row],\n",
    "                                    max_length=512,\n",
    "                                    truncation=True,\n",
    "                                    padding='max_length',\n",
    "                                    return_tensors='pt')\n",
    "        tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "        tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "    tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "    tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n",
    "\n",
    "    outputs = model(**tokens)\n",
    "    outputs.keys()\n",
    "\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    embeddings.shape\n",
    "\n",
    "    #mean pooling\n",
    "    mask = tokens['attention_mask'].unsqueeze(-1).expand(embeddings.size()).float()\n",
    "\n",
    "    #mask embeddings\n",
    "    mask_embeddings = embeddings * mask\n",
    "\n",
    "    #summed embeddings\n",
    "    summed = torch.sum(mask_embeddings, dim=1)\n",
    "\n",
    "    #counts\n",
    "    counts = torch.clamp(mask.sum(dim=1), min=1e-9)\n",
    "\n",
    "    #mean pooled \n",
    "    mean_pooled = summed/counts\n",
    "\n",
    "    mean_pooled = mean_pooled.detach().numpy()\n",
    "\n",
    "    # calculate cosine similarity for all rows using mean_pooled and cosine similarity\n",
    "    cosine_sim = cosine_similarity(mean_pooled, mean_pooled)\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "transformer = FunctionTransformer(process_data, validate=False)\n",
    "pipe = Pipeline([('transformer', transformer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|\u001b[32m          \u001b[0m| 0/15 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Processing: 100%|\u001b[32m██████████\u001b[0m| 15/15 [31:39<00:00, 126.65s/it]\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = pipe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "pickle.dump(cosine_sim, open(\"test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open saved model\n",
    "cosine_sim = pickle.load(open(\"test.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second, create a reverse map of indices and descriptions\n",
    "indices = pd.Series(df.index, index=df['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now we create a function recomender that will recommend simmilar products, function must take item_id and count as parameters\n",
    "\n",
    "# # talk_to_search = 'are solar panels worth it'\n",
    "# # top_n_results = 3\n",
    "\n",
    "# def recomender(talk_to_search, top_n_results):\n",
    "   \n",
    "#     count = top_n_results\n",
    "\n",
    "#     id = df.loc[df['title'] == talk_to_search].index.values[0]\n",
    "#        # Get the index of the item that matches the title\n",
    "#     idx = indices[id]\n",
    "\n",
    "#     # Get the pairwsie similarity scores of all movies with that talk\n",
    "#     sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "#     # Sort the movies based on the similarity scores\n",
    "#     sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=False)\n",
    "\n",
    "#     # Get the scores of the 10 most similar talks\n",
    "#     sim_scores = sim_scores[1:count+1]\n",
    "\n",
    "#     # Get the talk indices\n",
    "#     item_indicies = [i[0] for i in sim_scores]\n",
    "\n",
    "#     # Return the top 10 most similar talks\n",
    "#     top_talks_idx = df['transcript'].iloc[item_indicies].index[:count]\n",
    "#     # get author, talk using top_talks_idx\n",
    "#     top_talks_author = df['author'].iloc[item_indicies].values[:count]\n",
    "#     top_talks_talk = df['title'].iloc[item_indicies].values[:count]\n",
    "#     # get similarity scores using top_talks_idx\n",
    "#     top_n_results_sim_scores = [list(enumerate(cosine_sim[i]))[1][1] for i in top_talks_idx]\n",
    "\n",
    "   \n",
    "\n",
    "#     # create a result df \n",
    "#     result_df = pd.DataFrame({'author': top_talks_author, 'title': top_talks_talk, 'sim score': top_n_results_sim_scores})\n",
    "#     result_df = result_df.sort_values(by='sim score', ascending=False)\n",
    "\n",
    "#     # rename columns\n",
    "#     result_df.columns = ['author', 'title', 'sim score']\n",
    "\n",
    "#     return result_df\n",
    "\n",
    "\n",
    "\n",
    "#    # use indices to get 'author' and 'talk' columns from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(talk_to_search, top_n_results):\n",
    "    count = top_n_results\n",
    "\n",
    "    talk_indices = df[df['title'] == talk_to_search].index.values\n",
    "    if len(talk_indices) == 0:\n",
    "        print(\"Talk not found in DataFrame\")\n",
    "        return None\n",
    "\n",
    "    id = talk_indices[0]\n",
    "    if id >= len(indices):\n",
    "        print(\"Invalid talk index\")\n",
    "        return None\n",
    "\n",
    "    idx = indices[id]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=False)\n",
    "    sim_scores = sim_scores[1:count+1]\n",
    "    item_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Filter out invalid indices\n",
    "    item_indices = [i for i in item_indices if i < len(df)]\n",
    "\n",
    "    top_talks_author = df['author'].iloc[item_indices].values[:count]\n",
    "    top_talks_talk = df['title'].iloc[item_indices].values[:count]\n",
    "    top_n_results_sim_scores = [list(enumerate(cosine_sim[i]))[1][1] for i in item_indices]\n",
    "\n",
    "    result_df = pd.DataFrame({'author': top_talks_author, 'title': top_talks_talk, 'sim score': top_n_results_sim_scores})\n",
    "    result_df = result_df.sort_values(by='sim score', ascending=False)\n",
    "    result_df.columns = ['author', 'title', 'sim score']\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why are we so bad at reporting good news'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get title of talk at index 25\n",
    "df[df['author'] == 'Angus Hervey']['title'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>sim score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iseult Gillespie</td>\n",
       "      <td>the myth of zeus test</td>\n",
       "      <td>0.209797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will Guidara</td>\n",
       "      <td>the secret ingredients of great hospitality</td>\n",
       "      <td>0.119979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jerome Hunter</td>\n",
       "      <td>3 skills every middle school boy needs</td>\n",
       "      <td>0.108223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ryan Heffington</td>\n",
       "      <td>how dance can unleash your inner joy</td>\n",
       "      <td>0.042600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shannon Odell</td>\n",
       "      <td>how friendship affects your brain</td>\n",
       "      <td>-0.011371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                        title  sim score\n",
       "4  Iseult Gillespie                        the myth of zeus test   0.209797\n",
       "3      Will Guidara  the secret ingredients of great hospitality   0.119979\n",
       "2     Jerome Hunter       3 skills every middle school boy needs   0.108223\n",
       "0   Ryan Heffington         how dance can unleash your inner joy   0.042600\n",
       "1     Shannon Odell            how friendship affects your brain  -0.011371"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender('why are we so bad at reporting good news', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
