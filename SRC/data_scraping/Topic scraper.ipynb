{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import lxml.etree\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "topics_url = 'https://www.ted.com/topics'\n",
    "response = requests.get(topics_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# get topics under \"div class=\"text-sm xl:text-base xl:leading-md\"\n",
    "for topic in soup.find_all('div', class_='text-sm xl:text-base xl:leading-md'):\n",
    "    topic = topic.text.strip().lower()\n",
    "    if len(topic.split()) == 2:\n",
    "        topic = topic.split(\" \")[0] + \"+\" + topic.split(\" \")[1]\n",
    "    if len(topic.split()) == 3:\n",
    "        topic = topic.split(\" \")[0] + \"+\" + topic.split(\" \")[1] + \"+\" + topic.split(\" \")[2]\n",
    "    # if topic has only one word, remove spaces\n",
    "    elif len(topic.split()) == 1:\n",
    "        topic = topic.split()[0]\n",
    "    # if topic has only one word, remove spaces\n",
    "    topic = topic.replace(\"'\", \"%27\")\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activism',\n",
       " 'addiction',\n",
       " 'africa',\n",
       " 'aging',\n",
       " 'agriculture',\n",
       " 'ai',\n",
       " 'aids',\n",
       " 'algorithm',\n",
       " 'aliens',\n",
       " 'alzheimer%27s',\n",
       " 'ancient+world',\n",
       " 'animals',\n",
       " 'animation',\n",
       " 'antarctica',\n",
       " 'anthropocene',\n",
       " 'anthropology',\n",
       " 'archaeology',\n",
       " 'architecture',\n",
       " 'art',\n",
       " 'asia',\n",
       " 'asteroid',\n",
       " 'astrobiology',\n",
       " 'astronomy',\n",
       " 'atheism',\n",
       " 'audacious+project',\n",
       " 'augmented+reality',\n",
       " 'autism+spectrum+disorder',\n",
       " 'bacteria',\n",
       " 'beauty',\n",
       " 'bees',\n",
       " 'behavioral+economics',\n",
       " 'best of the web',\n",
       " 'big+bang',\n",
       " 'biodiversity',\n",
       " 'bioethics',\n",
       " 'biology',\n",
       " 'biomimicry',\n",
       " 'bionics',\n",
       " 'biosphere',\n",
       " 'biotech',\n",
       " 'birds',\n",
       " 'blindness',\n",
       " 'blockchain',\n",
       " 'body+language',\n",
       " 'books',\n",
       " 'botany',\n",
       " 'brain',\n",
       " 'brazil',\n",
       " 'buddhism',\n",
       " 'bullying',\n",
       " 'business',\n",
       " 'cancer',\n",
       " 'capitalism',\n",
       " 'chemistry',\n",
       " 'china',\n",
       " 'christianity',\n",
       " 'cities',\n",
       " 'climate+change',\n",
       " 'code',\n",
       " 'cognitive+science',\n",
       " 'collaboration',\n",
       " 'collective',\n",
       " 'comedy',\n",
       " 'communication',\n",
       " 'community',\n",
       " 'compassion',\n",
       " 'competition',\n",
       " 'computers',\n",
       " 'conducting',\n",
       " 'consciousness',\n",
       " 'conservation',\n",
       " 'consumerism',\n",
       " 'coral+reefs',\n",
       " 'coronavirus',\n",
       " 'corruption',\n",
       " 'countdown',\n",
       " 'creativity',\n",
       " 'crime',\n",
       " 'crispr',\n",
       " 'crowdsourcing',\n",
       " 'cryptocurrency',\n",
       " 'culture',\n",
       " 'curiosity',\n",
       " 'cyber+security',\n",
       " 'dance',\n",
       " 'dark+matter',\n",
       " 'data',\n",
       " 'death',\n",
       " 'decision-making',\n",
       " 'deextinction',\n",
       " 'demo',\n",
       " 'democracy',\n",
       " 'depression',\n",
       " 'design',\n",
       " 'dinosaurs',\n",
       " 'disability',\n",
       " 'discovery',\n",
       " 'disease',\n",
       " 'diversity',\n",
       " 'dna',\n",
       " 'driverless+cars',\n",
       " 'drones',\n",
       " 'drugs',\n",
       " 'ebola',\n",
       " 'ecology',\n",
       " 'economics',\n",
       " 'education',\n",
       " 'egypt',\n",
       " 'electricity',\n",
       " 'emotions',\n",
       " 'empathy',\n",
       " 'encryption',\n",
       " 'energy',\n",
       " 'engineering',\n",
       " 'entertainment',\n",
       " 'entrepreneur',\n",
       " 'environment',\n",
       " 'equality',\n",
       " 'ethics',\n",
       " 'europe',\n",
       " 'evolution',\n",
       " 'exercise',\n",
       " 'exploration',\n",
       " 'family',\n",
       " 'farming',\n",
       " 'fashion',\n",
       " 'fear',\n",
       " 'feminism',\n",
       " 'film',\n",
       " 'finance',\n",
       " 'fish',\n",
       " 'flight',\n",
       " 'food',\n",
       " 'forensics',\n",
       " 'fossil+fuels',\n",
       " 'friendship',\n",
       " 'fungi',\n",
       " 'future',\n",
       " 'gaming',\n",
       " 'gardening',\n",
       " 'gender',\n",
       " 'genetics',\n",
       " 'geography',\n",
       " 'geology',\n",
       " 'glaciers',\n",
       " 'global+issues',\n",
       " 'goals',\n",
       " 'government',\n",
       " 'grammar',\n",
       " 'graphic+design',\n",
       " 'happiness',\n",
       " 'health',\n",
       " 'health+care',\n",
       " 'hearing',\n",
       " 'heart',\n",
       " 'hinduism',\n",
       " 'history',\n",
       " 'homelessness',\n",
       " 'human+body',\n",
       " 'human+rights',\n",
       " 'humanities',\n",
       " 'humanity',\n",
       " 'humor',\n",
       " 'ideas',\n",
       " 'identity',\n",
       " 'illness',\n",
       " 'illusion',\n",
       " 'immigration',\n",
       " 'inclusion',\n",
       " 'india',\n",
       " 'indigenous+peoples',\n",
       " 'industrial+design',\n",
       " 'infrastructure',\n",
       " 'innovation',\n",
       " 'insects',\n",
       " 'international+development',\n",
       " 'international+relations',\n",
       " 'internet',\n",
       " 'interview',\n",
       " 'invention',\n",
       " 'investing',\n",
       " 'islam',\n",
       " 'journalism',\n",
       " 'judaism',\n",
       " 'justice+system',\n",
       " 'k-beauty',\n",
       " 'kids',\n",
       " 'language',\n",
       " 'law',\n",
       " 'leadership',\n",
       " 'lgbtqia+',\n",
       " 'library',\n",
       " 'life',\n",
       " 'literature',\n",
       " 'love',\n",
       " 'machine+learning',\n",
       " 'magic',\n",
       " 'manufacturing',\n",
       " 'maps',\n",
       " 'marine+biology',\n",
       " 'marketing',\n",
       " 'mars',\n",
       " 'math',\n",
       " 'media',\n",
       " 'medical+imaging',\n",
       " 'medical+research',\n",
       " 'medicine',\n",
       " 'meditation',\n",
       " 'memory',\n",
       " 'mental+health',\n",
       " 'metaverse',\n",
       " 'microbes',\n",
       " 'microbiology',\n",
       " 'middle+east',\n",
       " 'military',\n",
       " 'mindfulness',\n",
       " 'mission+blue',\n",
       " 'money',\n",
       " 'moon',\n",
       " 'motivation',\n",
       " 'museums',\n",
       " 'music',\n",
       " 'nanotechnology',\n",
       " 'nasa',\n",
       " 'natural+disaster',\n",
       " 'natural+resources',\n",
       " 'nature',\n",
       " 'neurology',\n",
       " 'neuroscience',\n",
       " 'nfts',\n",
       " 'nuclear+energy',\n",
       " 'ocean',\n",
       " 'online+privacy',\n",
       " 'pain',\n",
       " 'painting',\n",
       " 'paleontology',\n",
       " 'pandemic',\n",
       " 'parenting',\n",
       " 'performance',\n",
       " 'person',\n",
       " 'personal+growth',\n",
       " 'personality',\n",
       " 'philanthropy',\n",
       " 'philosophy',\n",
       " 'photography',\n",
       " 'physics',\n",
       " 'planets',\n",
       " 'plants',\n",
       " 'plastic',\n",
       " 'podcast',\n",
       " 'poetry',\n",
       " 'policy',\n",
       " 'politics',\n",
       " 'pollution',\n",
       " 'potential',\n",
       " 'poverty',\n",
       " 'pregnancy',\n",
       " 'primates',\n",
       " 'prison',\n",
       " 'product+design',\n",
       " 'productivity',\n",
       " 'prosthetics',\n",
       " 'protest',\n",
       " 'psychology',\n",
       " 'ptsd',\n",
       " 'public+health',\n",
       " 'public+space',\n",
       " 'public+speaking',\n",
       " 'quantum',\n",
       " 'race',\n",
       " 'refugees',\n",
       " 'relationships',\n",
       " 'religion',\n",
       " 'renewable+energy',\n",
       " 'resources',\n",
       " 'rivers',\n",
       " 'robots',\n",
       " 'rocket+science',\n",
       " 'science',\n",
       " 'science+fiction',\n",
       " 'self',\n",
       " 'sex',\n",
       " 'sexual+violence',\n",
       " 'shopping',\n",
       " 'sight',\n",
       " 'slavery',\n",
       " 'sleep',\n",
       " 'smell',\n",
       " 'social+change',\n",
       " 'social+media',\n",
       " 'society',\n",
       " 'sociology',\n",
       " 'software',\n",
       " 'solar+energy',\n",
       " 'solar+system',\n",
       " 'sound',\n",
       " 'south+america',\n",
       " 'space',\n",
       " 'spoken+word',\n",
       " 'sports',\n",
       " 'statistics',\n",
       " 'storytelling',\n",
       " 'street+art',\n",
       " 'string+theory',\n",
       " 'success',\n",
       " 'suicide',\n",
       " 'sun',\n",
       " 'surgery',\n",
       " 'surveillance',\n",
       " 'sustain',\n",
       " 'sustainability',\n",
       " 'synthetic+biology',\n",
       " 'talks',\n",
       " 'teaching',\n",
       " 'technology',\n",
       " 'ted',\n",
       " 'ted+books',\n",
       " 'ted+connects',\n",
       " 'ted+en+español',\n",
       " 'ted+fellows',\n",
       " 'ted+membership',\n",
       " 'ted+prize',\n",
       " 'ted+residency',\n",
       " 'ted+talk',\n",
       " 'ted+talks',\n",
       " 'ted-ed',\n",
       " 'tedmed',\n",
       " 'tedx',\n",
       " 'telescopes',\n",
       " 'television',\n",
       " 'terrorism',\n",
       " 'theater',\n",
       " 'time',\n",
       " 'toys',\n",
       " 'transgender',\n",
       " 'translation',\n",
       " 'transportation',\n",
       " 'travel',\n",
       " 'trees',\n",
       " 'trust',\n",
       " 'tv',\n",
       " 'typography',\n",
       " 'united+states',\n",
       " 'universe',\n",
       " 'urban+planning',\n",
       " 'ux+design',\n",
       " 'vaccines',\n",
       " 'veganism',\n",
       " 'violence',\n",
       " 'virtual+reality',\n",
       " 'virus',\n",
       " 'visualizations',\n",
       " 'vod',\n",
       " 'vulnerability',\n",
       " 'war',\n",
       " 'water',\n",
       " 'weather',\n",
       " 'wind+energy',\n",
       " 'women',\n",
       " 'women+in+business',\n",
       " 'work',\n",
       " 'work-life+balance',\n",
       " 'worklife',\n",
       " 'writing',\n",
       " 'youth',\n",
       " '3d+printing']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "landing_pages = []\n",
    "for i, topic in enumerate(topics): \n",
    "    pages = [str(i) for i in range(1, 2, 1)]\n",
    "    for page in pages:\n",
    "        topiclanding = \"https://www.ted.com/talks?page=\"+page+\"&topics%5B%5D=\"+topic\n",
    "        landing_pages.append(topiclanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'activism'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landing_pages[0].split('?')[1].split('&')[1].split('=')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing page 13/36:  36%|\u001b[32m███▌      \u001b[0m| 13/36 [00:25<00:45,  1.99s/it]\n",
      "Scraping activism:   0%|\u001b[33m          \u001b[0m| 1/366 [00:00<03:36,  1.69it/s]\n",
      "Processing page 13/36:  36%|\u001b[32m███▌      \u001b[0m| 13/36 [00:12<00:23,  1.00s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/patrickokwir/Desktop/Git_Projects/Ted-Talks-Recommender-System/SRC/Topic scraper.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickokwir/Desktop/Git_Projects/Ted-Talks-Recommender-System/SRC/Topic%20scraper.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m pbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickokwir/Desktop/Git_Projects/Ted-Talks-Recommender-System/SRC/Topic%20scraper.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m pbar\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing page \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(speaker)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, refresh\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/patrickokwir/Desktop/Git_Projects/Ted-Talks-Recommender-System/SRC/Topic%20scraper.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickokwir/Desktop/Git_Projects/Ted-Talks-Recommender-System/SRC/Topic%20scraper.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m: title[i]\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m: speaker[i]\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m: posted[i]\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mted.com\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mlink[i]\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m]}, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickokwir/Desktop/Git_Projects/Ted-Talks-Recommender-System/SRC/Topic%20scraper.ipynb#W4sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# print(speaker[i].text, posted[i].text, link[i].find('a')['href'], title[i].text, topic)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickokwir/Desktop/Git_Projects/Ted-Talks-Recommender-System/SRC/Topic%20scraper.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickokwir/Desktop/Git_Projects/Ted-Talks-Recommender-System/SRC/Topic%20scraper.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Add df to sqlite database\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickokwir/Desktop/Git_Projects/Ted-Talks-Recommender-System/SRC/Topic%20scraper.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# conn.commit()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickokwir/Desktop/Git_Projects/Ted-Talks-Recommender-System/SRC/Topic%20scraper.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# time.sleep(1)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "pbar = tqdm(total=len(landing_pages), dynamic_ncols=True, colour= 'yellow')\n",
    "for i, talk in enumerate(landing_pages):\n",
    "    # create dataframe for each talk, columns = title, author, date, url\n",
    "    df = pd.DataFrame(columns=['title', 'author', 'date', 'url'])\n",
    "    topiclanding = talk\n",
    "    response = requests.get(topiclanding)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    #find speaker name under h4 class=\"h12 talk-link__speaker\"\n",
    "    speaker = soup.find_all('h4', class_='h12 talk-link__speaker')\n",
    "    posted = soup.find_all('span', class_='meta__val')\n",
    "    # find href of the post under h4 tag a \n",
    "    link = soup.find_all('h4', class_='h9 m5 f-w:700')\n",
    "    title = link\n",
    "    topic = topiclanding.split('/')[-1].split('?')[1].split('&')[1].split('=')[1]\n",
    "\n",
    "    pbar.update(1)\n",
    "    pbar.set_description(f'Scraping {topic}', refresh=True)\n",
    "\n",
    "\n",
    "    # create progress bar\n",
    "    pbar = tqdm(total=len(speaker), dynamic_ncols=True, colour= 'green')\n",
    "    for i in range(len(speaker)):\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f\"Processing page {i+1}/{len(speaker)}\", refresh=True)\n",
    "        time.sleep(1)\n",
    "        df = df.append({'title': title[i].text, 'author': speaker[i].text, 'date': posted[i].text, 'url': 'ted.com'+link[i].find('a')['href']}, ignore_index=True)\n",
    "        # print(speaker[i].text, posted[i].text, link[i].find('a')['href'], title[i].text, topic)\n",
    "\n",
    "        # Add df to sqlite database\n",
    "        # iport\n",
    "        # conn = sqlite3.connect('talks.db')\n",
    "        # c = conn.cursor()\n",
    "        # c.execute(\"INSERT INTO topics (title, author, date, url) VALUES (?,?,?,?)\", (title[i].text, speaker[i].text, posted[i].text, 'ted.com'+link[i].find('a')['href']))\n",
    "        # conn.commit()\n",
    "        # time.sleep(1)\n",
    "    pbar.close()\n",
    "pbar.close()\n",
    "        # c.execute(\"SELECT * FROM topics\") \n",
    "        # rows = c.fetchall()\n",
    "        # pbar.set_description(f\"There are {len(rows)} records in the database\", refresh=True)\n",
    "        # conn.close()\n",
    "        # time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, author, date, url]\n",
       "Index: []"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
